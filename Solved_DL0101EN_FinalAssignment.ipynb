{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28409e69-abd3-451a-8fff-04b6bd972bd7",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 6>Regression Models with Keras</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65cf6c-4be7-4591-a0de-2d7f0c4e3430",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Keras is a high-level API for building deep learning models. It has gained favor for its ease of use and syntactic simplicity facilitating fast development.\n",
    "\n",
    "In this lab, Keras library will be used to build a regression model for a dataset about concrete compressive strength. The effects of the training epoch length and the structure of the hidden layer will be examined.\n",
    "\n",
    "<strong>The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:</strong>\n",
    "\n",
    "<strong>1. Cement</strong>\n",
    "\n",
    "<strong>2. Blast Furnace Slag</strong>\n",
    "\n",
    "<strong>3. Fly Ash</strong>\n",
    "\n",
    "<strong>4. Water</strong>\n",
    "\n",
    "<strong>5. Superplasticizer</strong>\n",
    "\n",
    "<strong>6. Coarse Aggregate</strong>\n",
    "\n",
    "<strong>7. Fine Aggregate</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc682b9-cf89-41a9-b74a-ce84cfa0efc4",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56c392b-60a8-47dd-9e4e-071518dac96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab76b5d-6846-4cd0-ae0a-3f051fceab85",
   "metadata": {},
   "source": [
    "## Download and view the Dataset\n",
    "\n",
    "Next step involves downloading the dataset and doing some preliminary analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae44d9d0-c8dd-4c08-ab45-4f9d90a2943b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (1030, 9)\n",
      "\n",
      "Checking for null values in dataset .....\n",
      "\n",
      "Cement                0\n",
      "Blast Furnace Slag    0\n",
      "Fly Ash               0\n",
      "Water                 0\n",
      "Superplasticizer      0\n",
      "Coarse Aggregate      0\n",
      "Fine Aggregate        0\n",
      "Age                   0\n",
      "Strength              0\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "print(\"The shape of the dataset is:\", concrete_data.shape)\n",
    "print()\n",
    "print(\"Checking for null values in dataset .....\")\n",
    "print()\n",
    "print(concrete_data.isnull().sum())\n",
    "print()\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4f155-b02f-400b-a0b3-2141723655f8",
   "metadata": {},
   "source": [
    "The **features columns** and **Strength column** are extracted to form our **predictors** and **target** for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96264503-f1ce-4daa-aa27-d0fb1a511b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
       "       'Coarse Aggregate', 'Fine Aggregate', 'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column\n",
    "predictors.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f267a6d-bf4e-4645-9571-8ad650b00881",
   "metadata": {},
   "source": [
    "To obtain off-sample dataset to test our trained model with, **30%** of the dataset is set aside using **train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8298892c-4384-4309-86a5-ec27b29d6205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf20f7-ea45-419c-a612-90ee7877f3d4",
   "metadata": {},
   "source": [
    "## Build the base Neural Network\n",
    "\n",
    "A function is defined for the regression model to facilitate easy calling to create required model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e76257-96cc-480c-8bdd-7ef986f7754c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model(n_layer, n_neurons, input_size, output_size):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    for i in range(n_layer+1):\n",
    "        if i == 0:\n",
    "            model.add(Dense(n_neurons, activation='relu', input_shape=(input_size,)))\n",
    "        elif i == n_layer:\n",
    "            model.add(Dense(output_size))\n",
    "        else:\n",
    "            model.add(Dense(n_neurons, activation='relu'))\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a36ecfc1-7b33-4a27-a274-acc5c00269e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f201963d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize some essential parameters for the model function\n",
    "input_size = predictors.shape[1] # number of predictors\n",
    "ouput_size = 1 # number of targets\n",
    "hidden_layers = 1\n",
    "nodes = 10   # number of neurons in the hidden layer\n",
    "Epochs = 50\n",
    "\n",
    "# build and fit the model\n",
    "model = regression_model(hidden_layers, nodes, input_size, ouput_size)\n",
    "model.fit(X_train, y_train, epochs=Epochs, verbose= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2fd44e6-35b9-4e69-95d6-fb34f36b057f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the base model on the test data is: 720.8025\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) # Perform some predictions using the test features\n",
    "print(\"The MSE of the base model on the test data is:\", f\"{mean_squared_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790f616b-ea70-47da-a399-7400b3961fc4",
   "metadata": {},
   "source": [
    "Performing an iterative training of the Regression model using random splitting of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ecadeca-b45a-4250-a9c1-6116668fa765",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 285.03110949999996\n",
      "Standard Deviation: 302.52007067903725\n"
     ]
    }
   ],
   "source": [
    "MSE = []\n",
    "for i in range(50):\n",
    "    \n",
    "    # Initialize some essential parameters for the model function\n",
    "    input_size = predictors.shape[1] # number of predictors\n",
    "    ouput_size = 1 # number of targets\n",
    "    hidden_layers = 1\n",
    "    nodes = 10   # number of neurons in the hidden layer\n",
    "    Epochs = 50\n",
    "    \n",
    "    # Randomly split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.30, random_state=i)\n",
    "\n",
    "    # build and fit the model\n",
    "    model = regression_model(hidden_layers, nodes, input_size, ouput_size)\n",
    "    model.fit(X_train, y_train, epochs=Epochs, verbose= False)\n",
    "    \n",
    "    y_pred = model.predict(X_test) # Perform some predictions using the test features\n",
    "    \n",
    "    # Append the MSE to the MSE list\n",
    "    MSE.append(float(f\"{mean_squared_error(y_test, y_pred):.6f}\"))\n",
    "\n",
    "# Print the mean and standard deviation of the list\n",
    "print(f'Mean: {np.mean(MSE): .6f}')\n",
    "print(f'Standard Deviation: {np.std(MSE): .6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a313aa6-a9b4-49e5-86d3-71174c9a97ab",
   "metadata": {},
   "source": [
    "## Demonstrating the effect of normalizing our dataset\n",
    "\n",
    "The data is normalized by subtracting the mean from the individual predictors and dividing by the standard deviation. Then, the normalized dataset is used to run the same operation as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab2bcae0-402d-4faa-9416-7a8a30170c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  351.696268\n",
      "Standard Deviation:  92.790012\n"
     ]
    }
   ],
   "source": [
    "# Normalizing our data\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "MSE = []\n",
    "for i in range(50):\n",
    "    \n",
    "    # Initialize some essential parameters for the model function\n",
    "    input_size = predictors.shape[1] # number of predictors\n",
    "    ouput_size = 1 # number of targets\n",
    "    hidden_layers = 1\n",
    "    nodes = 10   # number of neurons in the hidden layer\n",
    "    Epochs = 50\n",
    "    \n",
    "    # Randomly split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.30, random_state=i)\n",
    "\n",
    "    # build and fit the model\n",
    "    model = regression_model(hidden_layers, nodes, input_size, ouput_size)\n",
    "    model.fit(X_train, y_train, epochs=Epochs, verbose= False)\n",
    "    \n",
    "    y_pred = model.predict(X_test) # Perform some predictions using the test features\n",
    "    \n",
    "    # Append the MSE to the MSE list\n",
    "    MSE.append(float(f\"{mean_squared_error(y_test, y_pred):.6f}\"))\n",
    "\n",
    "# Print the mean and standard deviation of the list\n",
    "print(f'Mean: {np.mean(MSE): .6f}')\n",
    "print(f'Standard Deviation: {np.std(MSE): .6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7fc09e-2ccf-4c29-adb0-bc35a20328b4",
   "metadata": {},
   "source": [
    "I was expecting the mean of the **mean squared error (MSE)** to drop as the Features got normalized, but that wasn't the case. The noticable difference is with the **standard deviation (SD)**. The base model has a very high SD for the MSE, which implies that the MSE in the list varies over a wide range (This simply suggest that getting a good model with the unnormalized data will involve a high try and error), unlike the normalized dataset that has a lower SD for the MSE, therefore, its MSE's are closer to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee365bc-5964-43ae-9efc-f1ae3fb40263",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demonstrating the effect epoch length\n",
    "\n",
    "The epoch length is now doubled, from **50 to 100**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b2fb7af-90c6-4070-bb61-6220d0210e78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  172.560792\n",
      "Standard Deviation:  33.529968\n"
     ]
    }
   ],
   "source": [
    "MSE = []\n",
    "for i in range(50):\n",
    "    \n",
    "    # Initialize some essential parameters for the model function\n",
    "    input_size = predictors.shape[1] # number of predictors\n",
    "    ouput_size = 1 # number of targets\n",
    "    hidden_layers = 1\n",
    "    nodes = 10   # number of neurons in the hidden layer\n",
    "    Epochs = 100   # Increased from 50 to 100\n",
    "    \n",
    "    # Randomly split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.30, random_state=i)\n",
    "\n",
    "    # build and fit the model\n",
    "    model = regression_model(hidden_layers, nodes, input_size, ouput_size)\n",
    "    model.fit(X_train, y_train, epochs=Epochs, verbose= False)\n",
    "    \n",
    "    y_pred = model.predict(X_test) # Perform some predictions using the test features\n",
    "    \n",
    "    # Append the MSE to the MSE list\n",
    "    MSE.append(float(f\"{mean_squared_error(y_test, y_pred):.6f}\"))\n",
    "\n",
    "# Print the mean and standard deviation of the list\n",
    "print(f'Mean: {np.mean(MSE): .6f}')\n",
    "print(f'Standard Deviation: {np.std(MSE): .6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311458d0-0094-45e4-abc6-71cbec8b128f",
   "metadata": {},
   "source": [
    "Training for a longer Epoch did reduce the mean and SD of the MSE by a resoanable amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86e1c1-031e-4b33-900f-c6801047b47e",
   "metadata": {},
   "source": [
    "## Demonstrating the effect increasing the number of hidden layer in the neural network\n",
    "\n",
    "The epoch length is maintained at 50, while the hidden layers was increased to **3**, each having **10** nodes and ReLU activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "345cf5e5-282d-4657-b058-50231fb17010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  128.667700\n",
      "Standard Deviation:  17.923139\n"
     ]
    }
   ],
   "source": [
    "MSE = []\n",
    "for i in range(50):\n",
    "    \n",
    "    # Initialize some essential parameters for the model function\n",
    "    input_size = predictors.shape[1] # number of predictors\n",
    "    ouput_size = 1 # number of targets\n",
    "    hidden_layers = 3\n",
    "    nodes = 10   # number of neurons in the hidden layer\n",
    "    Epochs = 50\n",
    "    \n",
    "    # Randomly split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.30, random_state=i)\n",
    "\n",
    "    # build and fit the model\n",
    "    model = regression_model(hidden_layers, nodes, input_size, ouput_size)\n",
    "    model.fit(X_train, y_train, epochs=Epochs, verbose= False)\n",
    "    \n",
    "    y_pred = model.predict(X_test) # Perform some predictions using the test features\n",
    "    \n",
    "    # Append the MSE to the MSE list\n",
    "    MSE.append(float(f\"{mean_squared_error(y_test, y_pred):.6f}\"))\n",
    "\n",
    "# Print the mean and standard deviation of the list\n",
    "print(f'Mean: {np.mean(MSE): .6f}')\n",
    "print(f'Standard Deviation: {np.std(MSE): .6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a65d9-4333-4eaa-a7d8-e4c36219ace9",
   "metadata": {},
   "source": [
    "Increasing the number of hidden layers in the network increases the probability of the network to accurately learn the information in the dataset. So, this attributed to the significant drop in the mean and SD of the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b9d55-d41e-42f8-a680-ffc728c35bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa6dd15-2f19-45e9-8164-e4acfb5d308e",
   "metadata": {},
   "source": [
    "\n",
    "## Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2023-10-18  | 1.0  | Innocent  |  Created this notebook |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14586952-9175-477c-9a13-cce92d15253d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
